---
title: "Week 2 Assignment"
output: html_document
---

## 1 Generate uniformly distributed random numbers
### 1.1 Use runif()

Function runif(N,a,b) simulates N pseudo-random numbers uniformly distributed on [a,b].
```{r} 
set.seed(15) #provide repeatability
Sample<-runif(1000,0,1) #1000 pseudo-random numbers uniformly distributed between 0 and 1
```

### 1.2 Simulate Uniform Random Sample on [0,1] Using Random.org

From Random.org you can download binary sequence using library random.
This library is an interface to the web service of Random.org.

```{r}
library(random) #load package random
nFlips<-1000 #nFlips=1000
dataFromRandom<-randomNumbers(n=nFlips, min=0, max=1, col=1, base=2, check=TRUE) #randomNumber retrieves random integers with duplicates, n: The number of random integers to be retrieved. min: The minimum value for the returned numbers. max: The maximum value for the returned numbers. col: The number of columns for the return object. base = 2: The base for the random number is 2. check: Select whether quota at server should be checked first.

head(dataFromRandom) #returns first part of the dataset.
```

### 1.3 Downloading data from Random.org directly

```{r}
dataPath<-"~/Documents/UChicago/Courses/Statistical Analysis/Assignments/Week 2/"
dataFromRandom<-read.table(paste(dataPath,"randbyte.txt",sep="/")) #read in the date from the datapath
```

```{r}
dataFromRandom<-na.omit(unname(unlist(dataFromRandom))) #remove NAs, name attribute from the dataset,and flattens list and simplifies it to produce a vector which contains all the atomic components which occur in dataFromRandom
```

```{r}
dataFromRandom<-(as.vector(sapply(dataFromRandom,function(z) head(intToBits(z),8)))==1)*1  #sapply performs the user defined function(z) to margins of the dataset, which is transform data set z and read the first 8 lines of transformed raw vector (either 00 or 01). if it is equals 01, return TRUE, otherwise False, then convert logical false and true to 0 and 1
#
```

Variable dataFromRandom appears as a vector of 0 and 1 of length 1000.

### 1.4 Turning binary sequence to uniform random numbers

Turn your sequence of {0,1} into uniform random numbers on [0,1].

Create function that turns a sequence of zeros and ones of length n into decimal form.
```{r}
bitsToInt<-function(x) {
    packBits(rev(c(rep(FALSE, 32-length(x)%%32), as.logical(x))), "integer")
}

#rep(FALSE, 32-length(x)%%32) is repeating FALSE less or equal to 32 times, depending on the lenghth of x
# then the c() takes in the FALSEs and some 0s and 1s depending on values in x, also transform FALSEs as 0s
# finally we created a function using packBits which packs its input, in this case the reverse of c(), least-significant bit first to a integer vector.

bitsToInt(c(1,1,1,1,1,0))
```

Turn the sequence of zeros and ones dataFromRandom of length 1000 into a matrix with 10 columns and 100 rows
```{r}
Binary.matrix<-matrix(dataFromRandom,ncol=10)
head(Binary.matrix) # structure vector to matrix with 10 columns
```

Transform each row of the matrix into decimal format using bin2dec() and divide the numbers by 210 to make real numbers in [0,1].
```{r}
dataFromRandom.dec<-apply(Binary.matrix,1,bitsToInt)/2^10
head(dataFromRandom.dec) #apply bitsToInt over rows of the matrix and devide the number derived from each row by 2^10 to make 0 to 1 random numbers
```

All numbers in Decimal.Sample are between 0 and 1. This is your own equivalent of the sample obtained by runif().

## 2 Test random number generators

### 2.1 Test uniformity of distribution of both random number generators

#### 2.1.1 Using Sample generated by runif()

Analyze what was simulated by first looking at the histogram.
```{r}
Sample.histogram<-hist(Sample)
Sample.histogram #draw histogram and give all the argument values
```

**What does the histogram tell you about the distribution? Is it consistent with the goal of simulation?**

**The distribution is quite uniform between 0 and 1, so it is quite consistent with the goal of the simulation.**


Estimate mean and standard deviation of Sample.histogram$density.
```{r}
(Sample.histogram.mean<-mean(Sample.histogram$density)) #mean
(Sample.histogram.sd<-sd(Sample.histogram$density)) #standard deviation

```

```{r}
plot(Sample.histogram,freq=FALSE,ylim=c(0,Sample.histogram.mean+2*Sample.histogram.sd)) #plot the density, with y axis limit defined.
abline(h=Sample.histogram.mean)
abline(h=Sample.histogram.mean+1.96*Sample.histogram.sd,col="red",lty=2)
abline(h=Sample.histogram.mean-1.96*Sample.histogram.sd,col="red",lty=2) #add the mean and 95 % confidence interval of the mean
```

**What does the graph tell you about the observed distribution?**

**It's a very tight distribution with small standard deviation, each area between 0 and 1 is almost equally explored by runif() way of getting random number, and that there are equal amount of bars above and below the mean. So it's very close to a real uniform distribution**

Estimate moments of Sample.
```{r}
(Sample.mean<-mean(Sample))
(Sample.variance<-var(Sample))
```

**What do you conclude about the estimated distribution from the moments?**

**It is very close to real uniform distribution between 0 and 1, which has mean of 0.5 and variance of 1/12**


Check the summary of the simulated sample.
```{r}
summary(Sample)
```

**What do you think is the best way of estimating uniform distribution over unknown interval?**

**Summary statistics such as quantiles, mean, minimum and maximum as well as histogram plotting the frequency of the numbers.**


#### 2.1.2 Repeat the same steps to test uniformity of the sample from Random.org

```{r}
Sample.histogram<-hist(dataFromRandom.dec)
Sample.histogram
(Sample.histogram.mean<-mean(Sample.histogram$density))
(Sample.histogram.sd<-sd(Sample.histogram$density))
```


```{r}
plot(Sample.histogram,freq=FALSE,ylim=c(0,Sample.histogram.mean+2*Sample.histogram.sd))
abline(h=Sample.histogram.mean)
abline(h=Sample.histogram.mean+1.96*Sample.histogram.sd,col="red",lty=2)
abline(h=Sample.histogram.mean-1.96*Sample.histogram.sd,col="red",lty=2)
```

```{r}
(Sample.mean<-mean(dataFromRandom.dec))
(Sample.variance<-var(dataFromRandom.dec))
summary(dataFromRandom.dec)
```

**The data from Random.org looks less uniform than produced from runif() with larger standard deviation of the density, however it's very likely to be due to smaller sample size **

### 2.2 Test independence of the sequence of zeros and ones

#### 2.2.1 Turning point test
Turning point test is used to check if a sequence of numbers is i.i.d. (independent identically distributed).
The test is based on the number of turning points in the sequence.
The number of turning points is the number of maxima and minima in the series.
Let T be the number of turning points in a sample of length n large enough.
Then the statistic of the test has standard normal distribution.

The test is performed by turning.point.test() in package randtests

```{r}
suppressWarnings(library(randtests)) #load randomness testing package
turning.point.test(dataFromRandom.dec) #run turning point test on the data set
```

The null hypothesis tested by turning point test is randomness (i.i.d.). The alternative is serial correlation in the sequence. Thus, if the test returns a very small p-value the randomness needs to be rejected.

**In this case we do not reject null hypothesis that the data from Random.org is random**


#### 2.2.2 Test frequency by Monobit test
To perform Monobit test you need to transform your {0,1} sample into {-1,1}.
Illustrate the test on the sequence simulated in the previous lecture. We created the sequence of coin tosses:

```{r}
dataFromRandom.plusminus1<-(dataFromRandom-.5)*2 #0 and 1 minus 0.5 then times two, transformed to -1 and 1.
```

Recall from the lecture notes that monobit test of randomness is based on the statistic s. 
where Ri is the i-th random number, summation is done over all N=nFlips random numbers. 
erfc is the complimentary error function, a special function complimentary to error function erf=1-erfc.
Both functions can be easily calculated in R with the help of pnorm:

```{r}
erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1 #error function 
erfc <- function(x) 2 * pnorm(x * sqrt(2), lower = FALSE) #complimentary error function
```

The complimentary error function looks like:
```{r}
plot(seq(from=-3,to=3,by=.05),erfc(seq(from=-3,to=3,by=.05)),type="l",xlab="x",ylab="erfc(x") 
```

To test the sequence Ri check the value erfc(S).If the P-value or erfc(S) is less or equal than 0.01 the sequence fails the test.
```{r}
erfc(abs(sum(dataFromRandom.plusminus1)/sqrt(2*nFlips)))
```

**Since the p value is 1, it shows that the Random.org sequence passes.**

Now check each of the sub-sequences created earlier:
```{r}
plot(erfc(abs(apply(matrix(dataFromRandom.plusminus1,ncol=50),1,sum))/sqrt(2*50)),ylab="P-values of 20 runs",ylim=c(-0.05,1))
abline(h=.01,col="red") 
```

**How many runs out of 20 fail the test?**

**I made the critical p-value red and can see none of the runs fail the test, the following line also shows the same result**

```{r}
sum(erfc(abs(apply(matrix(dataFromRandom.plusminus1,ncol=50),1,sum))/sqrt(2*50))<=.01)
```

## 3 Invent a random number generator

Think about possible sources of true or pseudo-random sequences of {0,1} and choose one or two of them.Conduct the tests described in the previous section.

1. Description of your random number generator

* We can first generate a large amount of random numbers with defined max and min and calculate the median of these random numbers.  Then whether the numbers each are larger or smaller than the median would be random sequence of {False,True} and can be transformed to {0,1}.
* Also when deviding the random numbers with their defined maximum, we will generate pseudo random uniform distribution between [0,1].

2. Generated sequence

Generate numbers which are 10000 numbers from 1 to 500, compare them with the median of all generated numbers
```{r}
set.seed(500)
numbers <- sample(1:500, 10000, replace=TRUE)
binary.seq <- as.vector((numbers > median(numbers))*1)
```

3. Results of the uniformity test

Divide the numbers by the maximum possible number 500 to get 10000 decimal numbers between [0,1]. 
```{r}
random.dec<-numbers/500
head(random.dec)
```

```{r}
q3.histogram<-hist(random.dec)
q3.histogram.mean<-mean(q3.histogram$density)
q3.histogram.sd<-sd(q3.histogram$density)

plot(q3.histogram,freq=FALSE,ylim=c(0,q3.histogram.mean+2*q3.histogram.sd))
abline(h=q3.histogram.mean)
abline(h=q3.histogram.mean+1.96*q3.histogram.sd,col="red",lty=2)
abline(h=q3.histogram.mean-1.96*q3.histogram.sd,col="red",lty=2)

(q3.mean<-mean(random.dec))

(q3.variance<-var(random.dec))

summary(random.dec)
```

**It seems to be a good approximation of uniform distribution, with mean of 0.5 and variance of 1/12**

4. Results of the frequency test

Change the binary sequence to {-1,1} sequence. 
```{r}
binary.seq.plusminus1<-(binary.seq-.5)*2
```

Check the error function value. 
```{r}
erfc(abs(sum(binary.seq.plusminus1)/sqrt(2*nFlips)))
```

**Since it's not smaller than 0.01, it passes the test**. 

Check each of the sub-sequences created earlier:
```{r}
plot(erfc(abs(apply(matrix(binary.seq.plusminus1,ncol=100),1,sum))/sqrt(2*100)),ylab="P-values of 100 runs")
abline(h=.01,col='red')
sum(erfc(abs(apply(matrix(binary.seq.plusminus1,ncol=100),1,sum))/sqrt(2*100))<=.01)
```

**3 of the 100 tests fails, but it doesn't seem too bad.**

5. Results of the turning point test

```{r}
turning.point.test(random.dec)
```

**It passes the turning point test since the p-value is large enough**

## 4 Monte Carlo Method
### 4.1 Scratch off quote of the day: fuction download

Download function ScratchOffMonteCarlo() contained in a binary file ScratchOffMonteCarlo.rda from the web site, put it in a folder with path and import it into R.
```{r}
dataPath<-"~/Documents/UChicago/Courses/Statistical Analysis/Assignments/Week 2/"
load(file=paste(dataPath,'ScratchOffMonteCarlo.rda',sep='/'))
```

### 4.2 Simulate pseudo-random poins [x,y] on [0,100]×[0,100]
Select a number o points nSample.

Simulate a sample of length 2*nSample from uniform distribution on [0,100] and turn it into a (nSample×2) matrix.
Use a seed of your choice my.seed.

```{r}
nSample<-2000
my.seed<-1
set.seed(my.seed)
xy<-runif(2*nSample,0,100) #) #Throw nSample simulated points on square [0,100]×[0,100] to scratch off some of yellow paint.
xy<-matrix(xy,ncol=2)
head(xy)
```

```{r}
ScratchOffMonteCarlo(xy)
```

Take a note of the percentage scratched off returned by ScratchOffMonteCarlo(xy).

By changing nSample and my.seed try to make the quote of the day readable with minimum sample size.
What percent you needed to scratch off to make the quote readable?

* **"Size = 200","Open (%)= 1.96"; "Size = 1000", "Open (%)= 9.48"; "Size = 2000","Open (%)= 18.23"; "Size = 5000","Open (%)= 39.57". So Same seed(my.seed = 317), with larger size, openness increases**
* **"my.seed = 1","Open (%)= 18.09"; "my.seed = 317","Open (%)= 18.23"; "my.seed = 2000", "Open (%)= 18.12"; "my.seed = 12345","Open (%)= 18". So Same size (Size = 2000), with larger size, openness does not vary too much and there is no trend**
* **For me, at about 96% and sample size equal to 35000 I can read the quote: The purpose of models is not to fit the data, but sharpen the questions. - Samuel Karlin**

### 4.3 Simulate quasi-random poins [x,y] on [0,100]×[0,100]
function runif() can be replaced by sobol() from library randtoolbox.

```{r}
suppressWarnings(library(randtoolbox))
```

Run sobol() first time with the default set for parameter init=T.

```{r}
my.seed<-1
set.seed(my.seed)
nSample<-10
xy<-sobol(nSample,dim=2,init=T)*100
```

Then make init=F if you want to generate different sample every time or keep it equal to T if you want repeated samples.

```{r}
nSample<-18000
xy<-sobol(nSample,dim=2,init=T,scrambling = T,seed=my.seed)*100

plot(xy)
```
```{r}
ScratchOffMonteCarlo(xy)
```
**Again, by changing nSample and my.seed try to make the quote of the day readable with minimum sample size.What percent you needed to scratch off to make the quote readable?**

* **"Size = 200","Open (%)= 2"; "Size = 1000", "Open (%)= 9.97"; "Size = 2000","Open (%)= 19.77"; "Size = 5000","Open (%)= 44.63". So Same seed(my.seed = 317), with larger size, openness increases**
* **"my.seed = 1","Open (%)= 19.95"; "my.seed = 317","Open (%)= 19.77"; "my.seed = 2000", "Open (%)= 19.69"; "my.seed = 12345","Open (%)= 19.19". So Same size (Size = 2000), with larger size, openness does not vary too much but does decrease in this case**
* **For me, with my.seed= 1, at about 95% and sample size equal to 18000 I can read the quote**


**Which of the Monte Carlo methods makes the quote readable sooner?**

* **sobol is faster, with same seed, my.seed =1, the sample size required to reach ~95% scratch off for sobol (18000) is a little over half of what's required of runif (32000) **


**Which parameters nSample and my.seed gave you the best result, what percent of the yellow paing you were able to scratch off by each method? Changing which of the two parameters plays more significant role?**

* **As discussed above, increasing nSample has much more significant role in getthing the paint scratched off fast, whereas my.seed does not impact the result too much, in the sobol case, increasing the number of my.seed actually decrease the openness slightly with constant nSample. **

##5 Test
```{r}
dataPath<-"~/Documents/UChicago/Courses/Statistical Analysis/Assignments/Week 2"
dat <- read.table(paste(dataPath,'Week2_Test_Sample.csv',sep = '/'), header=TRUE)
```

dat[1] - mean value of normal distribution;
dat[2] - standard deviation of normal distribution;
dat[3] - intensity of exponential distribution;
dat[4]:dat[503] sample from uniform distribution on [0.1].
Using this sample, create:

Sample datNorm from normal distribution with mean dat[1] and standard deviation dat[2];
Sample datExp from exponential distribution with intensity dat[3].

```{r}
datuni <- dat$x[4:503]
datNorm <- qnorm(p= datuni, mean= dat$x[1], sd= dat$x[2])
#transform uniform distribution to normal distribution
datExp <- qexp(p= datuni, rate = dat$x[3]) #transform uniform distribution to exponential distribution
```


```{r}
res<-cbind(datNorm=datNorm,datExp=datExp) #Create matrix res with the two samples
write.csv(res, file = paste(dataPath,'result.csv',sep="/"), row.names = F) #Save res to a file and upload the file using left sidebar.
```
