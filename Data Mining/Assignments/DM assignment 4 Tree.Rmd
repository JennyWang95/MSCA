---
title: "DM Assignment 4 Tree"
author: "Elyse Zhang"
date: "7/28/2018"
output: html_document
---

```{r}
dataPath = '/Users/Elyse/Documents/UChicago/Courses/Summer 2018/Data Mining/Assignments/Assignment 3'
German.Credit = read.csv(file=paste(dataPath,"German.Credit.csv",sep="/"),header=TRUE,sep=",")
str(German.Credit)
```


```{r}
for (i in c(1,2,4,5,7:13,15:21))
  German.Credit[,i] = as.factor(German.Credit[,i])

str(German.Credit)
```


```{r}
set.seed(101)
train.indexes = sample(nrow(German.Credit), size=0.7*nrow(German.Credit))

Train.comp = German.Credit[train.indexes,]
Holdout.comp = German.Credit[-train.indexes,]
```


## 1. Classification Tree model
```{r}
library(rpart)
set.seed(101)
Train.nocp=rpart(Train.comp,control=rpart.control(cp=0,minsplit=30,xval=10))
# 10-fold cross validation xval
# the number of surrogate splits retained in the output. If this is set to zero the compute time will be reduced, since approximately half of the computational time (other than setup) is used in the search for surrogate splits
```


## 2. 
```{r}
printcp(Train.nocp)
plotcp(Train.nocp)
```

* The lowest xerror is 0.88293, with cp = 0.0146341 (to avoid rounding issues, we will grab it from the result)

```{r}
Train.cp = rpart(Train.comp,control =rpart.control(cp=Train.nocp$cptable[2,1]))
```


##3. Confusion matrix
```{r}
table(Train.comp[,1],predict(Train.cp,type="class"))
round(prop.table(table(Train.comp[,1],predict(Train.cp,type="class")),1),2) #Effectiveness
#round(prop.table(table(Train.comp[,1],predict(Train.cp,type="class")),2),2) #efficiency

ct.predict.train = predict(Train.cp,type="class")
```

* Type 1 error is a too high. This poses a larger risk than type 2 error in this case.

```{r}
 par(mai = c(0.1,0.1,0.1,0.1))
 plot(Train.cp,main="Classification Tree: German Credit Train",col=3, compress=TRUE, branch=0.2,uniform=TRUE)
 text(Train.cp,cex=0.6,col=4,use.n=TRUE,fancy=TRUE, fwidth=0.4, fheight=0.4,bg=c(5))

library(RColorBrewer)
library(rpart.plot)
rpart.plot(Train.cp,roundint=FALSE)
```

* We can see 6 interactions due to 5 splits. Some significant ones are:
  + If the customer has account balance = 3 and 4 which means 0 <= < 200 DM or >= 200 DM or checking account for at least 1 year, they are immediately classified as having good credibility. That's 46% of the training sample and the probablity that they have good credit are 0.88. The interaction of Value.Saving.Stocks only applies to customers who don't have an account or have no balance in the account. 
  + If the customer has payment of status of previous credit = 3 and 4, meaning paid back previous credits at this bank or no problems with current credits at this bank, they are immediately classified as having good credibility. That's 10% of the training sample and the probablity that they have good credit are 0.76. The interaction of Purpose only applies to customers whose payment of status of previous credit are 0,1,2 problemetic or hesitant in paying back. 
* Overall, the tree is very intepretable. 
* Terminal nodes are very clear in that green is good creditability, blue is bad, with darker color representing stronger prediction.


## 4. Holdout validation
```{r}
table(Holdout.comp[,1],predict(Train.cp,newdata=Holdout.comp[,-1],type="class"))
round(prop.table(table(Holdout.comp[,1],predict(Train.cp,newdata=Holdout.comp[,-1],type="class")),1),2)

ct.predict.test = predict(Train.cp,newdata=Holdout.comp[,-1],type="class")
```

* Unfortunately, results are not very stable. We did not predict bad creditability customers at all.  

##5. Comparison of Tree and Logistic Models
* Tree model is more intepretable than logistic model. 
* In the logistic model, our Type 1 error is 0.25, whereas here our Type 1 error is 0.65. The purpose of predicting customers' creditability is to be able to identify the customers who might default. In that case the Logistic model (with adjusted threshold) is much better than the Tree model.
* In the logistic model, our type 2 error is 0.34, higher than the tree model 0.11. We will end up rejecting some more potential good lenders with logistic model than tree model.


```{r}
write.csv(ct.predict.train, file = "ct.predict.train.csv",row.names=FALSE)
write.csv(ct.predict.test, file = "ct.predict.test.csv",row.names=FALSE)

```




